package service

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"strings"

	"github.com/Martin4208/Nexus/apps/api-gateway/internal/client"
	"github.com/Martin4208/Nexus/apps/api-gateway/internal/db"
	"github.com/google/uuid"
	"github.com/sqlc-dev/pqtype"
)

// AnalysisService ã¯åˆ†ææ©Ÿèƒ½ã®ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‹…å½“
type AnalysisService struct {
	queries      *db.Queries
	aiClient     client.AIWorkerClient
	qdrantClient client.QdrantClient
	ollamaClient client.OllamaClient
}

// NewAnalysisService ã¯æ–°ã—ã„AnalysisServiceã‚’ä½œæˆ
func NewAnalysisService(
	queries *db.Queries,
	aiClient client.AIWorkerClient,
	qdrantClient client.QdrantClient,
	ollamaClient client.OllamaClient,
) *AnalysisService {
	return &AnalysisService{
		queries:      queries,
		aiClient:     aiClient,
		qdrantClient: qdrantClient,
		ollamaClient: ollamaClient,
	}
}

// CreateAnalysis ã¯åˆ†æã‚¸ãƒ§ãƒ–ã‚’ä½œæˆã—ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ã‚’é–‹å§‹
func (s *AnalysisService) CreateAnalysis(
	ctx context.Context,
	workspaceID uuid.UUID,
	title string,
	description *string,
	analysisType string,
	config map[string]interface{},
) (*db.Analysis, error) {
	// Step 1: config ã‚’ JSONB ã«å¤‰æ›
	var configJSON pqtype.NullRawMessage
	if config != nil {
		configBytes, err := json.Marshal(config)
		if err != nil {
			return nil, fmt.Errorf("failed to marshal config: %w", err)
		}
		configJSON = pqtype.NullRawMessage{
			RawMessage: configBytes,
			Valid:      true,
		}
	}

	// Step 2: description ã‚’ sql.NullString ã«å¤‰æ›
	var desc sql.NullString
	if description != nil {
		desc = sql.NullString{String: *description, Valid: true}
	}

	// Step 3: DB ã«åˆ†æã‚¸ãƒ§ãƒ–ã‚’ä½œæˆï¼ˆstatus = pendingï¼‰
	analysis, err := s.queries.CreateAnalysis(ctx, db.CreateAnalysisParams{
		WorkspaceID:  workspaceID,
		Title:        title,
		Description:  desc,
		AnalysisType: analysisType,
		Config:       configJSON,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create analysis: %w", err)
	}

	log.Printf("âœ… Analysis created: %s (type: %s)", analysis.ID, analysisType)

	// Step 4: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§åˆ†æå‡¦ç†ã‚’é–‹å§‹ï¼ˆGoroutineï¼‰
	go func() {
		// æ–°ã—ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆå…ƒã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ã¯åˆ‡ã‚Šé›¢ã™ï¼‰
		bgCtx := context.Background()

		log.Printf("ğŸ”„ Starting background analysis: %s", analysis.ID)

		if err := s.ProcessAnalysis(bgCtx, workspaceID, analysis.ID); err != nil {
			log.Printf("âŒ Analysis failed: %s - %v", analysis.ID, err)
		} else {
			log.Printf("âœ… Analysis completed: %s", analysis.ID)
		}
	}()

	// Step 5: ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆ202 Acceptedï¼‰
	return &analysis, nil
}

// ProcessAnalysis ã¯å®Ÿéš›ã®åˆ†æå‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰
func (s *AnalysisService) ProcessAnalysis(
	ctx context.Context,
	workspaceID uuid.UUID,
	analysisID uuid.UUID,
) error {
	// Step 1: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ processing ã«æ›´æ–°
	err := s.queries.UpdateAnalysisStatus(ctx, db.UpdateAnalysisStatusParams{
		ID:           analysisID,
		Status:       "processing",
		ErrorMessage: sql.NullString{Valid: false},
	})
	if err != nil {
		return fmt.Errorf("failed to update status to processing: %w", err)
	}

	// Step 2: åˆ†ææƒ…å ±ã‚’å–å¾—
	analysis, err := s.queries.GetAnalysis(ctx, db.GetAnalysisParams{
		ID:          analysisID,
		WorkspaceID: workspaceID,
	})
	if err != nil {
		s.markAsFailed(ctx, analysisID, err)
		return fmt.Errorf("failed to get analysis: %w", err)
	}

	// Step 3: å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
	documents, err := s.getTargetDocuments(ctx, workspaceID, analysis.Config)
	if err != nil {
		s.markAsFailed(ctx, analysisID, err)
		return fmt.Errorf("failed to get documents: %w", err)
	}

	if len(documents) == 0 {
		err := fmt.Errorf("no documents found for analysis")
		s.markAsFailed(ctx, analysisID, err)
		return err
	}

	log.Printf("ğŸ“„ Processing %d documents for analysis %s", len(documents), analysisID)

	// Step 4: åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†åˆ†å²
	var results []db.CreateAnalysisResultParams
	switch analysis.AnalysisType {
	case "summary":
		results, err = s.processSummary(ctx, workspaceID, documents)
	case "keyword_extraction":
		results, err = s.processKeywordExtraction(ctx, workspaceID, documents)
	case "entity_recognition":
		results, err = s.processEntityRecognition(ctx, workspaceID, documents)
	default:
		err = fmt.Errorf("unsupported analysis type: %s", analysis.AnalysisType)
	}

	if err != nil {
		s.markAsFailed(ctx, analysisID, err)
		return fmt.Errorf("analysis processing failed: %w", err)
	}

	// Step 5: çµæœã‚’ DB ã«ä¿å­˜
	for _, result := range results {
		result.AnalysisID = analysisID
		_, err := s.queries.CreateAnalysisResult(ctx, result)
		if err != nil {
			log.Printf("âš ï¸ Failed to save result: %v", err)
		}
	}

	// Step 6: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ completed ã«æ›´æ–°
	err = s.queries.UpdateAnalysisStatus(ctx, db.UpdateAnalysisStatusParams{
		ID:           analysisID,
		Status:       "completed",
		ErrorMessage: sql.NullString{Valid: false},
	})
	if err != nil {
		return fmt.Errorf("failed to update status to completed: %w", err)
	}

	return nil
}

// getTargetDocuments ã¯åˆ†æå¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
func (s *AnalysisService) getTargetDocuments(
	ctx context.Context,
	workspaceID uuid.UUID,
	config pqtype.NullRawMessage,
) ([]db.ListDocumentsRow, error) {
	// config ã‹ã‚‰ document_ids ã‚’å–å¾—
	var documentIDs []uuid.UUID

	if config.Valid && len(config.RawMessage) > 0 {
		var configMap map[string]interface{}
		if err := json.Unmarshal(config.RawMessage, &configMap); err == nil {
			if ids, ok := configMap["document_ids"].([]interface{}); ok {
				for _, id := range ids {
					if idStr, ok := id.(string); ok {
						if docID, err := uuid.Parse(idStr); err == nil {
							documentIDs = append(documentIDs, docID)
						}
					}
				}
			}
		}
	}

	// document_ids ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã‚Œã‚‰ã‚’å–å¾—
	if len(documentIDs) > 0 {
		// TODO: ç‰¹å®šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã§çµã‚Šè¾¼ã‚€å®Ÿè£…
		// ç¾åœ¨ã® ListDocuments ã¯ ID ãƒ•ã‚£ãƒ«ã‚¿ã«éå¯¾å¿œãªã®ã§ã€å…¨ä»¶å–å¾—å¾Œã«ãƒ•ã‚£ãƒ«ã‚¿
		allDocs, err := s.queries.ListDocuments(ctx, db.ListDocumentsParams{
			WorkspaceID: workspaceID,
			Limit:       1000,
			Offset:      0,
		})
		if err != nil {
			return nil, err
		}

		// ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
		var filtered []db.ListDocumentsRow
		for _, doc := range allDocs {
			for _, targetID := range documentIDs {
				if doc.ID == targetID {
					filtered = append(filtered, doc)
					break
				}
			}
		}
		return filtered, nil
	}

	// document_ids ãŒç©ºã®å ´åˆã¯ã€workspaceå†…ã®å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å¯¾è±¡
	return s.queries.ListDocuments(ctx, db.ListDocumentsParams{
		WorkspaceID: workspaceID,
		Limit:       1000,
		Offset:      0,
	})
}

// processSummary ã¯è¦ç´„åˆ†æã‚’å®Ÿè¡Œ
func (s *AnalysisService) processSummary(
	ctx context.Context,
	workspaceID uuid.UUID,
	documents []db.ListDocumentsRow,
) ([]db.CreateAnalysisResultParams, error) {
	log.Printf("ğŸ“ Starting summary analysis for %d documents", len(documents))

	// Step 1: å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
	var allChunks []string
	maxChunks := 100 // æœ€å¤§100ãƒãƒ£ãƒ³ã‚¯ã¾ã§ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™å¯¾ç­–ï¼‰

	for _, doc := range documents {
		chunks, err := s.queries.GetDocumentChunks(ctx, db.GetDocumentChunksParams{
			DocumentID: doc.ID,
			Limit:      int32(maxChunks),
			Offset:     0,
		})
		if err != nil {
			log.Printf("âš ï¸ Failed to get chunks for doc %s: %v", doc.ID, err)
			continue
		}

		for _, chunk := range chunks {
			allChunks = append(allChunks, chunk.Content)
			if len(allChunks) >= maxChunks {
				break
			}
		}

		if len(allChunks) >= maxChunks {
			break
		}
	}

	if len(allChunks) == 0 {
		return nil, fmt.Errorf("no chunks found in documents")
	}

	log.Printf("ğŸ“Š Collected %d chunks for summarization", len(allChunks))

	// Step 2: ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
	combinedText := strings.Join(allChunks, "\n\n---\n\n")

	prompt := fmt.Sprintf(`ä»¥ä¸‹ã®è³‡æ–™ç¾¤ã‚’åˆ†æã—ã€æ—¥æœ¬èªã§è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€è¦ç´„ã®è¦ä»¶ã€‘
1. ä¸»è¦ãªãƒ†ãƒ¼ãƒã‚’3-5å€‹æŠ½å‡ºã—ã¦ãã ã•ã„
2. å„ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦2-3æ–‡ã§ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„
3. é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤ªå­—ã§å¼·èª¿ã—ã¦ãã ã•ã„
4. å…¨ä½“ã®çµè«–ã‚’æœ€å¾Œã«1æ®µè½ã§è¿°ã¹ã¦ãã ã•ã„

ã€è³‡æ–™å†…å®¹ã€‘
%s

ã€è¦ç´„ã€‘`, combinedText)

	// Step 3: LLMï¼ˆOllamaï¼‰ã§è¦ç´„ç”Ÿæˆ
	log.Printf("ğŸ¤– Calling Ollama for summarization...")
	summary, err := s.ollamaClient.Generate(ctx, "phi3:mini", prompt)
	if err != nil {
		return nil, fmt.Errorf("failed to generate summary: %w", err)
	}

	log.Printf("âœ… Summary generated: %d characters", len(summary))

	// Step 4: çµæœã‚’è¿”ã™
	contentJSON, _ := json.Marshal(map[string]string{
		"summary": summary,
	})

	result := db.CreateAnalysisResultParams{
		ResultType:  "summary",
		Content:     contentJSON,
		ImageUrl:    sql.NullString{Valid: false},
		MinioBucket: sql.NullString{Valid: false},
		MinioKey:    sql.NullString{Valid: false},
		Metadata:    pqtype.NullRawMessage{Valid: false},
	}

	return []db.CreateAnalysisResultParams{result}, nil
}

// processKeywordExtraction ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºåˆ†æã‚’å®Ÿè¡Œ
func (s *AnalysisService) processKeywordExtraction(
	ctx context.Context,
	workspaceID uuid.UUID,
	documents []db.ListDocumentsRow,
) ([]db.CreateAnalysisResultParams, error) {
	// TODO: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã®å®Ÿè£…
	return nil, fmt.Errorf("keyword_extraction is not implemented yet")
}

// processEntityRecognition ã¯å›ºæœ‰è¡¨ç¾æŠ½å‡ºåˆ†æã‚’å®Ÿè¡Œ
func (s *AnalysisService) processEntityRecognition(
	ctx context.Context,
	workspaceID uuid.UUID,
	documents []db.ListDocumentsRow,
) ([]db.CreateAnalysisResultParams, error) {
	// TODO: å›ºæœ‰è¡¨ç¾æŠ½å‡ºã®å®Ÿè£…
	return nil, fmt.Errorf("entity_recognition is not implemented yet")
}

// markAsFailed ã¯åˆ†æã‚’å¤±æ•—ã¨ã—ã¦ãƒãƒ¼ã‚¯
func (s *AnalysisService) markAsFailed(ctx context.Context, analysisID uuid.UUID, err error) {
	updateErr := s.queries.UpdateAnalysisStatus(ctx, db.UpdateAnalysisStatusParams{
		ID:     analysisID,
		Status: "failed",
		ErrorMessage: sql.NullString{
			String: err.Error(),
			Valid:  true,
		},
	})
	if updateErr != nil {
		log.Printf("âš ï¸ Failed to mark analysis as failed: %v", updateErr)
	}
}

// jsonEscape ã¯æ–‡å­—åˆ—ã‚’JSONç”¨ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
func jsonEscape(s string) string {
	b, _ := json.Marshal(s)
	return string(b)
}

// ListAnalyses ã¯åˆ†æä¸€è¦§ã‚’å–å¾—
func (s *AnalysisService) ListAnalyses(
	ctx context.Context,
	workspaceID uuid.UUID,
	status *string,
	limit int,
	offset int,
) ([]db.ListAnalysesRow, int64, error) {
	// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ã®æº–å‚™
	var statusFilter sql.NullString
	if status != nil {
		statusFilter = sql.NullString{String: *status, Valid: true}
	}

	// ä¸€è¦§å–å¾—
	analyses, err := s.queries.ListAnalyses(ctx, db.ListAnalysesParams{
		WorkspaceID: workspaceID,
		Status:      statusFilter,
		Limit:       int32(limit),
		Offset:      int32(offset),
	})
	if err != nil {
		return nil, 0, fmt.Errorf("failed to list analyses: %w", err)
	}

	// ç·æ•°å–å¾—
	total, err := s.queries.CountAnalyses(ctx, db.CountAnalysesParams{
		WorkspaceID: workspaceID,
		Status:      statusFilter,
	})
	if err != nil {
		return nil, 0, fmt.Errorf("failed to count analyses: %w", err)
	}

	return analyses, total, nil
}

// GetAnalysis ã¯åˆ†æè©³ç´°ã‚’å–å¾—
func (s *AnalysisService) GetAnalysis(
	ctx context.Context,
	workspaceID uuid.UUID,
	analysisID uuid.UUID,
) (*db.Analysis, error) {
	analysis, err := s.queries.GetAnalysis(ctx, db.GetAnalysisParams{
		ID:          analysisID,
		WorkspaceID: workspaceID,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to get analysis: %w", err)
	}

	return &analysis, nil
}

// GetAnalysisResults ã¯åˆ†æçµæœã‚’å–å¾—
func (s *AnalysisService) GetAnalysisResults(
	ctx context.Context,
	analysisID uuid.UUID,
) ([]db.AnalysisResult, error) {
	results, err := s.queries.ListAnalysisResults(ctx, analysisID)
	if err != nil {
		return nil, fmt.Errorf("failed to get analysis results: %w", err)
	}

	return results, nil
}

// DeleteAnalysis ã¯åˆ†æã‚’å‰Šé™¤ï¼ˆSoft deleteï¼‰
func (s *AnalysisService) DeleteAnalysis(
	ctx context.Context,
	workspaceID uuid.UUID,
	analysisID uuid.UUID,
) error {
	err := s.queries.DeleteAnalysis(ctx, db.DeleteAnalysisParams{
		ID:          analysisID,
		WorkspaceID: workspaceID,
	})
	if err != nil {
		return fmt.Errorf("failed to delete analysis: %w", err)
	}

	return nil
}
